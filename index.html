<!DOCTYPE html><html lang="en"><head>
	<meta name="generator" content="Hugo 0.135.0">
    <meta charset="utf-8">
<title>Second Year PhD Presentation</title>
<meta name="description" content="Symbolic Knowledge Injection &amp; Extraction for Autonomous Learning">
<meta name="author" content="Matteo Magnini">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><link rel="stylesheet" href="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-js/dist/reset.css">
<link rel="stylesheet" href="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-js/dist/reveal.css">
  <link rel="stylesheet" href="https://MatteoMagnini.github.io/second-year-phd-presentation/css/custom-theme.min.2abad5fe437215b2f3f11f57457d5ca4fe1939107bc4d1ecec59f2e1c3f5ad23.css" id="theme"><link rel="stylesheet" href="https://MatteoMagnini.github.io/second-year-phd-presentation/highlight-js/solarized-dark.min.css">
<link rel="stylesheet" href="https://gitcdn.link/repo/DanySK/css-blur-animation/master/blur.css">
<link href="https://fonts.googleapis.com/css?family=Roboto Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Oxygen Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu Mono" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">
  </head>
  <body>
    
    <div class="reveal">
      <div class="slides">
  

    <section data-noprocess="" data-shortcode-slide="" data-background-iframe="https://MatteoMagnini.github.io/second-year-phd-presentation/boids.html" data-preload="true" data-transition="zoom">
<h1 id="symbolic-knowledge-injection--extraction-for-autonomous-learning">Symbolic Knowledge Injection &amp; Extraction for Autonomous Learning</h1>
<p><strong>Second Year PhD report</strong></p>
<p>🎤 <em>Matteo Magnini</em>, supervisor <strong>Andrea Omicini</strong></p>
<p>📧 <a href="mailto:gianluca.aguzzi@unibo.it">matteo.magnini@unibo.it</a></p>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true">
<h2 class="highlight" id="context">Context</h2>
<h3 class="accent" id="fundamentals">Fundamentals</h3>
<div class="container">
<span class="fragment col">
  <h4 id="symbolic-knowledge">Symbolic Knowledge</h4>
<br>
$$
\forall x \, \text{Man}(x) \implies \text{Mortal}(x)
$$
<p>$$
\text{Man}(\text{Socrates})
$$</p>
<p><i class="fa fa-arrow-down" aria-hidden="true"></i></p>
<p>$$
\text{Mortal}(\text{Socrates})
$$</p>
<p>All those knowledge representations where there are symbols carrying <strong>meaning</strong>: logic rules, traffic signs, sentences in natural language, etc.</p>
</span>
<span class="fragment col">
  <h4 id="sub-symbolic-models">Sub-symbolic models</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/second-year-phd-presentation/nn-brain-shape.png" style="height:297px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>Models that are based on <strong>numerical values</strong> and do not have a symbolic meaning like neural networks.</p>
</span>
<span class="fragment col">
  <h4 id="intelligent-systems">Intelligent Systems</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/second-year-phd-presentation/intelligent-hybrid-systems.svg" style="height:297px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>Intelligent systems incorporate knowledge, possibly <strong>both symbolic and sub-symbolic</strong>, to make decisions.</p>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true">
<h2 class="highlight" id="context-1">Context</h2>
<h3 class="accent" id="symbolic-knowledge-injection-ski">Symbolic Knowledge Injection (SKI)</h3>
<div class="container">
<span class="fragment col">
  <h4 id="constraining">Constraining</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/second-year-phd-presentation/workflow-constraining.png" style="height:225px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>The training process is <em>guided</em> by the loss function that incorporates the knowledge <strong>penalising</strong> the model when it makes predictions that <strong>violates</strong> it.</p>
</span>
<span class="fragment col">
  <h4 id="embedding">Embedding</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/second-year-phd-presentation/workflow-embedding.png" style="height:225px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>The symbolic knowledge is <em>embedded</em> into a sub-symbolic representation.
The embeddings are provided as <strong>additional input</strong> to the neural network.</p>
</span>
</div>
<div class="container">
<span class="fragment col">
  <figure class="">
    <img src="https://MatteoMagnini.github.io/second-year-phd-presentation/workflow-structuring.png" style="height:225px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
</span>
<span class="fragment col">
  <h4 id="structuring">Structuring</h4>
<p>The network <em>architecture is modified</em> to include symbolic knowledge.
Some neurons and connection are designed to <strong>mimic</strong> the symbolic knowledge.</p>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true">
<h2 class="highlight" id="context-2">Context</h2>
<h3 class="accent" id="symbolic-knowledge-extraction-ske">Symbolic Knowledge Extraction (SKE)</h3>
<div class="container">
<span class="fragment col">
  <h4 id="data">Data</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/second-year-phd-presentation/iris-flower.png" style="height:270px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>The well known Iris dataset is used to train a neural network.</p>
</span>
<span class="fragment col">
  <h4 id="sub-symbolic-model">Sub-symbolic model</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/second-year-phd-presentation/nn-iris.png" style="height:270px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>A neural network is trained to classify the Iris dataset.
A human <strong>can’t understand</strong> how the network makes decisions by inspecting it.</p>
</span>
<span class="fragment col">
  <h4 id="symbolic-knowledge">Symbolic knowledge</h4>
<figure class="">
    <img src="https://MatteoMagnini.github.io/second-year-phd-presentation/decision-tree-iris.png" style="height:270px; ; max-width: 95vw;max-height: 80vh;object-fit: contain;">
    <figcaption>  </figcaption>
  </figure>
<p>A decision tree is generated from the neural network to extract symbolic knowledge.
The decision tree is <strong>interpretable</strong> by humans.</p>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true">
<h2 class="highlight" id="current-literature-limitations">Current literature limitations</h2>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="technology">Technology</h4>
<ul>
<li>The vast majority of the literature articles <em>lack the implementation</em> of the proposed methods.</li>
<li>The ones that do, only have the code to run the experiments (if still available and maintained).</li>
<li>Only a handful of works provide a library to use the proposed method.</li>
</ul>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="methodology">Methodology</h4>
<ul>
<li>SKI (resp. SKE) methods primarily focus in achieving <em>better performance</em> for the educated (resp. surrogate) model.</li>
<li>There is a lack of works that explore qualitative aspects of the model, a.k.a. <em>Quality of Service (QoS)</em>.</li>
<li>SKI can be used for other purposes rather than improving the model performance, like ensuring <em>fairness</em> quality.</li>
</ul>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="vision">Vision</h4>
<ul>
<li>SKI and SKE methods are virtually used only to solve <em>toy-problems</em> to validate the approach.</li>
<li>The potential of these methods in <em>real-world applications</em> is not explored.</li>
<li>Also, the <em>conjunct</em> use of SKI and SKE is not explored.</li>
</ul>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true">
<h2 class="highlight" id="proposed-approach">Proposed approach</h2>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="roadmap">Roadmap</h4>
<ul>
<li>Study the current literature to understand the state-of-the-art in SKI and SKE.</li>
<li>Design tools to support the implementations of new and already existing SKI and SKE methods.</li>
<li>Formalise QoS metrics for SKI and SKE methods.</li>
</ul>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="intelligent-systems-branch">Intelligent Systems branch</h4>
<ul>
<li>Design and implement intelligent systems that make use of SKI and SKE methods for real-world applications.</li>
</ul>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="fairness-branch">Fairness branch</h4>
<ul>
<li>Explore the use of SKI methods to ensure fairness in AI systems.</li>
<li>Design a specific language to express fairness constraints.</li>
</ul>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true">
<h2 class="highlight" id="contributions">Contributions</h2>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="systematic-literature-review">Systematic Literature Review</h4>
<ul>
<li>“G. Ciatto et al., <em>Symbolic Knowledge Extraction and Injection with Subsymbolic Predictors: A Systematic Literature Review</em>, in journal <span class="ok">ACM Computing Surveys 2024</span>”</li>
</ul>
</span>
<span class="fragment col">
  <h4 class="accent" id="technologies">Technologies</h4>
<ul>
<li>“M. Magnini et al., <em>On the Design of PSyKI: A Platform for Symbolic Knowledge Injection into Sub-symbolic Predictors</em>, in workshop <span class="ok">EXTRAAMAS 2022</span>”, publicly available at <a href="https://github.com/psykei/psyki-python">github.com/psykei/psyki-python</a></li>
<li>PSyKE, implementation only, publicly available at <a href="https://github.com/psykei/psyke-python">github.com/psykei/psyki-python</a></li>
</ul>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="ski-methods">SKI methods</h4>
<ul>
<li>“M. Magnini et al., <em>KINS: Knowledge Injection via Network Structuring</em>, in workshop <span class="ok">CILC 2022</span>”</li>
<li>“M. Magnini et al., <em>Knowledge injection of Datalog rules via Neural Network Structuring with KINS</em>, in journal <span class="ok">Logic and Computation 2023</span>”</li>
<li>“M. Magnini et al., <em>A view to a KILL: knowledge injection via lambda layer</em>, in workshop <span class="ok">WOA 2022</span>”</li>
</ul>
</span>
<span class="fragment col">
  <h4 class="accent" id="quality-of-service">Quality of Service</h4>
<ul>
<li>“A. Agiollo et al., <em>Symbolic knowledge injection meets intelligent agents: QoS metrics and experiments</em>, in journal <span class="ok">Autonomous Agents and Multi-Agent Systems 2023</span>”</li>
<li>“A. Rafanelli et al., <em>An Empirical Study on the Robustness of Knowledge Injection Techniques Against Data Degradation</em>, in workshop <span class="ok">WOA 2024</span>”</li>
</ul>
</span>
</div>
</section><section>
<h2 class="highlight" id="contributions-1">Contributions</h2>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="intelligent-systems">Intelligent systems</h4>
<ul>
<li>“M. Magnini et al., <em>Symbolic knowledge extraction for explainable nutritional recommenders</em>, in journal <span class="ok">Computer Methods and Programs in Biomedicine 2023</span>”</li>
<li>“G. Ciatto et al., <em>A General-Purpose Protocol for Multi-agent Based Explanations</em>, in workshop <span class="ok">EXTRAAMAS 2023</span>”</li>
</ul>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="ski-and-ske-conjunct">SKI and SKE conjunct</h4>
<ul>
<li>“M. Magnini et al., <em>Bridging Symbolic and Sub-Symbolic AI: Towards Cooperative Transfer Learning in Multi-Agent Systems</em>” in workshop <span class="ok">AIxIA DP 2022</span></li>
</ul>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="fairness">Fairness</h4>
<ul>
<li>“M. Magnini et al., <em>Enforcing Fairness via Constraint Injection with FaUCI</em>, in workshop <span class="ok">AEQUITAS 2024</span>”</li>
</ul>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true">
<h2 class="highlight" id="and-then-llms-happened">And then LLMs happened</h2>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="large-language-models">Large Language Models</h4>
<p>LLMs are huge neural networks (up to hundreds of billions of parameters) that are trained on a large corpus of text data.
Generally, LLMs work by <strong>predicting the most plausible token</strong> given the previous tokens in a sentence.
In the last years, the success of LLM has been world-wide recognised, and they are successfully used in applications of different domains.</p>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="ske-with-llm">SKE with LLM</h4>
<p>LLMs can be exploited to <strong>extract</strong> symbolic knowledge about a particular domain of interest.
The process can be done by iteratively querying the LLM with a set of questions following a specific protocol.
From the answers, a symbolic representation can be generated.</p>
</span>
</div>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="ski-with-llm">SKI with LLM</h4>
<p>Conversely, LLMs can operate by <strong>exploiting external (symbolic) knowledge</strong> like textual documents, ontologies, databases, etc.
This knowledge can be provided with two different strategies:</p>
<ul>
<li><em>Fine-tuning</em>: similar to the traditional fine-tuning process, re-training the LLM with the new data.</li>
<li><em>Retrieval-augmented generation (RAG)</em>: retrieval mechanism to get relevant information from the external knowledge and then generation phase.</li>
</ul>
</span>
</div>
</section>
<section data-noprocess="" data-shortcode-slide="" data-auto-animate="true">
<h2 class="highlight" id="contributions-2">Contributions</h2>
<div class="container">
<span class="fragment col">
  <h4 class="accent" id="applications-ski-and-ske-with-llms">Applications, SKI and SKE with LLMs</h4>
<ul>
<li>“M. Magnini et al., <em>Actively Learning Ontologies from LLMs: First Results (Extended Abstract)</em>, in workshop <span class="ok">DL 2024</span>”</li>
<li>“S. Montagna et al., <em>LLM-based Solutions for Healthcare Chatbots: a Comparative Analysis</em>, in workshop <span class="ok">PERCOM 2024</span>”</li>
</ul>
</span>
</div>
<h2 class="highlight" id="challenges-and-future-work">Challenges and Future work</h2>
<div class="container">
<span class="fragment col">
  <ul>
<li><em>Reliability</em> of SKI/SKE systems and LLMs. E.g., extracted/injected knowledge is sound? Are there hallucinations? etc.</li>
<li><em>Fairness</em>, are there bias in the LLMs? If positive, how to mitigate it?</li>
<li><em>Closing the loop</em> between SKI and SKE, how to use the extracted knowledge to improve the injected one continuously?</li>
<li><em>Real-world applications</em>, explore new tasks where SKI/SKE and LLMs (possibly with multiple roles) can be used.</li>
</ul>
</span>
</div></section>

  


</div>
      

    </div>
<script type="text/javascript" src="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-hugo/object-assign.js"></script>

<a href="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-js/dist/print/" id="print-location" style="display: none;"></a>

<script type="application/json" id="reveal-hugo-site-params">{"custom_theme":"custom-theme.scss","custom_theme_compile":true,"custom_theme_options":{"enablesourcemap":true,"targetpath":"css/custom-theme.css"},"height":900,"highlight_theme":"solarized-dark","history":true,"mermaid":[{"startOnLoad":false,"theme":"default"}],"slide_number":true,"theme":"serif","transition":"slide","transition_speed":"normal","width":1440}</script>
<script type="application/json" id="reveal-hugo-page-params">null</script>

<script src="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-js/dist/reveal.js"></script>


  
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-js/plugin/zoom/zoom.js"></script>
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-js/plugin/notes/notes.js"></script>
  
  
  <script type="text/javascript" src="https://MatteoMagnini.github.io/second-year-phd-presentation/reveal-js/plugin/notes/notes.js"></script>




<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }

  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };

  var revealHugoPlugins = { 
    plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom ]
   };
  var revealHugoSiteParams = JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);
  var revealHugoPageParams = JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);
  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams),
    camelize(revealHugoPlugins));
  Reveal.initialize(options);
</script>






  

  

  



    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
</script>

<script type="text/javascript" id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

    
  

</body></html>